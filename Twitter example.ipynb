{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "import string\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "#for first time using nltk\n",
    "# nltk.download ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_variable='clean_text'\n",
    "target_feature='category'\n",
    "splits=10\n",
    "stop_words = stopwords.words('english') \n",
    "dataset_location=\"datasets/Twitter and Reddit Sentimental analysis Dataset/Twitter_Data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_variable='clean_text'\n",
    "target_feature='category'\n",
    "dataset_location=\"datasets/Sentiment Analysis for Financial News/all-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature='airline_sentiment'\n",
    "text_variable='text'\n",
    "dataset_location='datasets/Twitter US Airline Sentiment/Tweets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"(http\\S+|http)\", \"\", txt) # remove links \n",
    "    txt = re.sub('[^a-zA-Z ]+', '', txt) #only allows for letters\n",
    "    txt = ' '.join([PorterStemmer().stem(word=word) for word in txt.split(\" \") if word not in stop_words ]) # stem & remove stop words\n",
    "    return txt\n",
    "\n",
    "def print_model_performance(target,predicted):\n",
    "#     training_sample = model.predict(X_train)\n",
    "#     testing_sample = model.predict(X_test)\n",
    "#     print('training ')\n",
    "#     print('train accuracy ',accuracy_score(training_sample, y_train))\n",
    "#     print('\\n testing  ')\n",
    "#     print('test average accuracy ',accuracy_score(testing_sample, y_test))\n",
    "#     print(confusion_matrix( y_test,testing_sample))\n",
    "    print('outcome of training')\n",
    "    print(classification_report( target,predicted))   #uncomment if you want to see full report \n",
    "    print('test average accuracy ',accuracy_score( target,predicted))\n",
    "    print(confusion_matrix( target,predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(text, threshold=0.05, engl=True):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    if engl:\n",
    "        trans = text\n",
    "    else:\n",
    "        trans = translator.translate(text).text\n",
    "    score = analyser.polarity_scores(trans)\n",
    "    lb = score['compound']\n",
    "    return lb\n",
    "    if lb >= threshold:\n",
    "        return 1\n",
    "    elif (lb > -threshold) and (lb < threshold):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "def train_test_split_features(train, test,train_feature, target_feature,vectorise):\n",
    "    y_train = train[target_feature]   \n",
    "    X_train = train[train_feature]\n",
    "    y_test = test[target_feature]   \n",
    "    X_test = test[train_feature]\n",
    "    feature_names=[]\n",
    "    if(vectorise):\n",
    "        vect = TfidfVectorizer(min_df=5, ngram_range=(1, 4)) # create Count vectorizer.\n",
    "        X_train = vect.fit(X_train).transform(X_train) # transform text_train  into a vector \n",
    "        X_test = vect.transform(X_test) \n",
    "        feature_names = vect.get_feature_names() # to return all words used in vectorizer\n",
    "  \n",
    "    return X_train, X_test, y_train, y_test, feature_names\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "#get this working a bit better later\n",
    "def all_models():\n",
    "    #Using the recomended classifiers\n",
    "    #https://arxiv.org/abs/1708.05070\n",
    "    GBC = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "    RFC = RandomForestClassifier(n_estimators=500, max_features=0.25, criterion=\"entropy\")\n",
    "    SVM = SVC(C = 0.01, gamma=0.1, kernel=\"poly\", degree=3, coef0=10.0)\n",
    "    ETC = ExtraTreesClassifier(n_estimators=1000, max_features=\"log2\", criterion=\"entropy\")\n",
    "    LR = LogisticRegression(C=1.5,fit_intercept=True)\n",
    "    # Models that were not included in the paper not from SKlearn\n",
    "    XGC = XGBClassifier()\n",
    "    CBC = CatBoostClassifier(silent=True)\n",
    "    light_gb = lgb.LGBMClassifier()\n",
    "    models=[(LR, \"linear_regression\"),(ETC, \"Extra_tree_classifier\"),(SVM, \"support_vector_classifier\"), (RFC, \"random_forest_classifier\"), (GBC, \"gradient_boosted_classifier\"),\n",
    "             (XGC, \"XGBoost\"),(light_gb,\"Light_GBM\"), (CBC, \"catboost_classifier\")]\n",
    "    models=[(LR, \"linear_regression\"), (GBC, \"gradient_boosted_classifier\"),\n",
    "             (XGC, \"XGBoost\"),(light_gb,\"Light_GBM\")]\n",
    "#     models=[(LR, \"linear_regression\"),(SVM, \"support_vector_classifier\"), \n",
    "#               (CBC, \"catboost_classifier\"),(XGC, \"XGBoost\")]\n",
    "#      (RFC, \"random_forest_classifier\"),(ETC, \"Extra_tree_classifier\"),(GBC, \"gradient_boosted_classifier\"),\n",
    "#                (CBC, \"catboost_classifier\")]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_run(df):\n",
    "    train, test = train_test_split(df, test_size=0.99)\n",
    "    train, validation = train_test_split(train, test_size=0.125)\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data_df = pd.read_csv(dataset_location,encoding='ISO-8859-1',header='infer',)\n",
    "#data_df.columns = [target_feature, text_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica plu youv ad commerci experi tacki</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>virginamerica didnt today must mean need take ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica realli aggress blast obnoxi ente...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica realli big bad thing</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>americanair thank got differ flight chicago</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>americanair leav  minut late flight warn commu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>americanair pleas bring american airlin blackb...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>americanair money chang flight dont answer pho...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>americanair  ppl need  know mani seat next fli...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "0                            virginamerica dhepburn said           neutral\n",
       "1        virginamerica plu youv ad commerci experi tacki          positive\n",
       "2      virginamerica didnt today must mean need take ...           neutral\n",
       "3      virginamerica realli aggress blast obnoxi ente...          negative\n",
       "4                     virginamerica realli big bad thing          negative\n",
       "...                                                  ...               ...\n",
       "14635        americanair thank got differ flight chicago          positive\n",
       "14636  americanair leav  minut late flight warn commu...          negative\n",
       "14637  americanair pleas bring american airlin blackb...           neutral\n",
       "14638  americanair money chang flight dont answer pho...          negative\n",
       "14639  americanair  ppl need  know mani seat next fli...           neutral\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(dataset_location) \n",
    "\n",
    "data_df[text_variable] = data_df[text_variable].astype(str)\n",
    "data_df[text_variable] = data_df[text_variable].apply(clean_text) \n",
    "data_df=data_df[[text_variable,target_feature]]\n",
    "data_df = data_df.dropna()\n",
    "# data_df,_,_=quick_run(data_df)\n",
    "data_df=data_df.reset_index(drop=True)\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22.68628454208374 seconds ---\n",
      "gradient_boosted_classifier\n",
      "--- 52.52271509170532 seconds ---\n",
      "XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 74.50928211212158 seconds ---\n",
      "Light_GBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 162.23888158798218 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_features(df, model, splits,features=text_variable,vectorise=True, predict_probability=False):\n",
    "    cv = KFold(n_splits=splits, random_state=42, shuffle=False)\n",
    "    full_prediciton=[]\n",
    "    for train_index, test_index in cv.split(df):\n",
    "        train, test = df.loc[train_index], df.loc[test_index]\n",
    "\n",
    "        X_train, X_test, y_train, y_test, feature_names=train_test_split_features(train,test,text_variable,target_feature, True)\n",
    "#         model = LogisticRegressionCV()\n",
    "        #to run faster\n",
    "#         model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        #print_model_performance(lgstc, X_train, X_test, y_train, y_test)\n",
    "        if (predict_probability==True):\n",
    "            prediction = model.predict_proba(X_test)\n",
    "        else:\n",
    "            prediction = model.predict(X_test)\n",
    "        full_prediciton.append(prediction)\n",
    "    predictions=[]\n",
    "\n",
    "    for set_of_prediction in full_prediciton:\n",
    "        for predicted in set_of_prediction:\n",
    "            predictions.append(predicted)\n",
    "    return predictions\n",
    "# to_dataset=data_df.copy()\n",
    "\n",
    "\n",
    "model_predicted_names=[]\n",
    "models=all_models()\n",
    "df_copy=data_df.copy()\n",
    "for model, name in models:\n",
    "    print(name)\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    predict_probability=True\n",
    "    predictions=run_features(df_copy,model,splits,predict_probability=predict_probability)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    predicted_name=name+'_prediction'\n",
    "    negative_prob=[]\n",
    "    neutral_prob=[]\n",
    "    positive_prob=[]\n",
    "    if (predict_probability):\n",
    "        for neg, neut,pos in predictions:\n",
    "            negative_prob.append(neg)\n",
    "            neutral_prob.append(neut)\n",
    "            positive_prob.append(pos)\n",
    "        neg_predictions=predicted_name+'_neg'\n",
    "        neut_predictions=predicted_name+'_neut'\n",
    "        pos_predictions=predicted_name+'_pos'\n",
    "        df_copy[neg_predictions]=negative_prob\n",
    "        df_copy[neut_predictions]=neutral_prob\n",
    "        df_copy[pos_predictions]=positive_prob\n",
    "\n",
    "        model_predicted_names.append(neg_predictions)\n",
    "        model_predicted_names.append(neut_predictions)\n",
    "        model_predicted_names.append(pos_predictions)\n",
    "        negative_prob.clear()\n",
    "        neutral_prob.clear()\n",
    "        positive_prob.clear()\n",
    "    else:\n",
    "#         df_copy[predicted_name]=predictions\n",
    "#         model_predicted_names.append(predicted_name)\n",
    "        df_copy[predicted_name]=predictions\n",
    "        model_predicted_names.append(predicted_name)\n",
    "\n",
    "        print_model_performance(df_copy[target_feature],predictions)\n",
    "        predictions.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(text, threshold=0.05, engl=True):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "    if engl:\n",
    "        trans = text\n",
    "    else:\n",
    "        trans = translator.translate(text).text\n",
    "\n",
    "    score = analyser.polarity_scores(trans)\n",
    "    lb = score['compound']\n",
    "    return lb\n",
    "    if lb >= threshold:\n",
    "        return 1\n",
    "    elif (lb > -threshold) and (lb < threshold):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['polarity']=df_copy[text_variable].apply(lambda text: TextBlob(text).sentiment.polarity)\n",
    "df_copy['subjectivity']=df_copy[text_variable].apply(lambda text: TextBlob(text).sentiment.subjectivity)\n",
    "df_copy['vader_sentiment']=df_copy[text_variable].apply(lambda tweet: sentiment_analyzer_scores(tweet))\n",
    "model_predicted_names.append('polarity')\n",
    "model_predicted_names.append('subjectivity')\n",
    "model_predicted_names.append('vader_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>linear_regression_prediction_neg</th>\n",
       "      <th>linear_regression_prediction_neut</th>\n",
       "      <th>linear_regression_prediction_pos</th>\n",
       "      <th>gradient_boosted_classifier_prediction_neg</th>\n",
       "      <th>gradient_boosted_classifier_prediction_neut</th>\n",
       "      <th>gradient_boosted_classifier_prediction_pos</th>\n",
       "      <th>XGBoost_prediction_neg</th>\n",
       "      <th>XGBoost_prediction_neut</th>\n",
       "      <th>XGBoost_prediction_pos</th>\n",
       "      <th>Light_GBM_prediction_neg</th>\n",
       "      <th>Light_GBM_prediction_neut</th>\n",
       "      <th>Light_GBM_prediction_pos</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.797402</td>\n",
       "      <td>0.163446</td>\n",
       "      <td>0.039152</td>\n",
       "      <td>0.765865</td>\n",
       "      <td>0.186492</td>\n",
       "      <td>0.047643</td>\n",
       "      <td>0.569338</td>\n",
       "      <td>0.348488</td>\n",
       "      <td>0.082174</td>\n",
       "      <td>0.658466</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>0.065769</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica plu youv ad commerci experi tacki</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.768217</td>\n",
       "      <td>0.103630</td>\n",
       "      <td>0.128153</td>\n",
       "      <td>0.859047</td>\n",
       "      <td>0.112271</td>\n",
       "      <td>0.028682</td>\n",
       "      <td>0.745079</td>\n",
       "      <td>0.164476</td>\n",
       "      <td>0.090446</td>\n",
       "      <td>0.717759</td>\n",
       "      <td>0.146752</td>\n",
       "      <td>0.135489</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>virginamerica didnt today must mean need take ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.842602</td>\n",
       "      <td>0.143376</td>\n",
       "      <td>0.014022</td>\n",
       "      <td>0.685881</td>\n",
       "      <td>0.271451</td>\n",
       "      <td>0.042667</td>\n",
       "      <td>0.614816</td>\n",
       "      <td>0.365109</td>\n",
       "      <td>0.020074</td>\n",
       "      <td>0.614650</td>\n",
       "      <td>0.358835</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica realli aggress blast obnoxi ente...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.758093</td>\n",
       "      <td>0.132768</td>\n",
       "      <td>0.109139</td>\n",
       "      <td>0.842462</td>\n",
       "      <td>0.105130</td>\n",
       "      <td>0.052408</td>\n",
       "      <td>0.766549</td>\n",
       "      <td>0.120340</td>\n",
       "      <td>0.113111</td>\n",
       "      <td>0.752354</td>\n",
       "      <td>0.146953</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica realli big bad thing</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.844298</td>\n",
       "      <td>0.036344</td>\n",
       "      <td>0.119358</td>\n",
       "      <td>0.931683</td>\n",
       "      <td>0.045590</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.840147</td>\n",
       "      <td>0.057549</td>\n",
       "      <td>0.102304</td>\n",
       "      <td>0.862668</td>\n",
       "      <td>0.043995</td>\n",
       "      <td>0.093338</td>\n",
       "      <td>-0.3500</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>americanair thank got differ flight chicago</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.089353</td>\n",
       "      <td>0.520496</td>\n",
       "      <td>0.390151</td>\n",
       "      <td>0.030135</td>\n",
       "      <td>0.115817</td>\n",
       "      <td>0.854048</td>\n",
       "      <td>0.042256</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.804744</td>\n",
       "      <td>0.047342</td>\n",
       "      <td>0.221495</td>\n",
       "      <td>0.731164</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>americanair leav  minut late flight warn commu...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.990954</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.941381</td>\n",
       "      <td>0.038121</td>\n",
       "      <td>0.020498</td>\n",
       "      <td>0.976462</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>0.957470</td>\n",
       "      <td>0.030969</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>-0.3000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>americanair pleas bring american airlin blackb...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.155839</td>\n",
       "      <td>0.627981</td>\n",
       "      <td>0.216181</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.431016</td>\n",
       "      <td>0.128583</td>\n",
       "      <td>0.571948</td>\n",
       "      <td>0.277073</td>\n",
       "      <td>0.150979</td>\n",
       "      <td>0.333125</td>\n",
       "      <td>0.350045</td>\n",
       "      <td>0.316829</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>americanair money chang flight dont answer pho...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.900002</td>\n",
       "      <td>0.090315</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>0.919845</td>\n",
       "      <td>0.063409</td>\n",
       "      <td>0.016746</td>\n",
       "      <td>0.915721</td>\n",
       "      <td>0.064107</td>\n",
       "      <td>0.020172</td>\n",
       "      <td>0.918684</td>\n",
       "      <td>0.072807</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>americanair  ppl need  know mani seat next fli...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.647267</td>\n",
       "      <td>0.294267</td>\n",
       "      <td>0.058466</td>\n",
       "      <td>0.622730</td>\n",
       "      <td>0.298452</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>0.485328</td>\n",
       "      <td>0.458647</td>\n",
       "      <td>0.056024</td>\n",
       "      <td>0.368919</td>\n",
       "      <td>0.558795</td>\n",
       "      <td>0.072286</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment  \\\n",
       "0                            virginamerica dhepburn said           neutral   \n",
       "1        virginamerica plu youv ad commerci experi tacki          positive   \n",
       "2      virginamerica didnt today must mean need take ...           neutral   \n",
       "3      virginamerica realli aggress blast obnoxi ente...          negative   \n",
       "4                     virginamerica realli big bad thing          negative   \n",
       "...                                                  ...               ...   \n",
       "14635        americanair thank got differ flight chicago          positive   \n",
       "14636  americanair leav  minut late flight warn commu...          negative   \n",
       "14637  americanair pleas bring american airlin blackb...           neutral   \n",
       "14638  americanair money chang flight dont answer pho...          negative   \n",
       "14639  americanair  ppl need  know mani seat next fli...           neutral   \n",
       "\n",
       "       linear_regression_prediction_neg  linear_regression_prediction_neut  \\\n",
       "0                              0.797402                           0.163446   \n",
       "1                              0.768217                           0.103630   \n",
       "2                              0.842602                           0.143376   \n",
       "3                              0.758093                           0.132768   \n",
       "4                              0.844298                           0.036344   \n",
       "...                                 ...                                ...   \n",
       "14635                          0.089353                           0.520496   \n",
       "14636                          0.990954                           0.006345   \n",
       "14637                          0.155839                           0.627981   \n",
       "14638                          0.900002                           0.090315   \n",
       "14639                          0.647267                           0.294267   \n",
       "\n",
       "       linear_regression_prediction_pos  \\\n",
       "0                              0.039152   \n",
       "1                              0.128153   \n",
       "2                              0.014022   \n",
       "3                              0.109139   \n",
       "4                              0.119358   \n",
       "...                                 ...   \n",
       "14635                          0.390151   \n",
       "14636                          0.002701   \n",
       "14637                          0.216181   \n",
       "14638                          0.009683   \n",
       "14639                          0.058466   \n",
       "\n",
       "       gradient_boosted_classifier_prediction_neg  \\\n",
       "0                                        0.765865   \n",
       "1                                        0.859047   \n",
       "2                                        0.685881   \n",
       "3                                        0.842462   \n",
       "4                                        0.931683   \n",
       "...                                           ...   \n",
       "14635                                    0.030135   \n",
       "14636                                    0.941381   \n",
       "14637                                    0.440400   \n",
       "14638                                    0.919845   \n",
       "14639                                    0.622730   \n",
       "\n",
       "       gradient_boosted_classifier_prediction_neut  \\\n",
       "0                                         0.186492   \n",
       "1                                         0.112271   \n",
       "2                                         0.271451   \n",
       "3                                         0.105130   \n",
       "4                                         0.045590   \n",
       "...                                            ...   \n",
       "14635                                     0.115817   \n",
       "14636                                     0.038121   \n",
       "14637                                     0.431016   \n",
       "14638                                     0.063409   \n",
       "14639                                     0.298452   \n",
       "\n",
       "       gradient_boosted_classifier_prediction_pos  XGBoost_prediction_neg  \\\n",
       "0                                        0.047643                0.569338   \n",
       "1                                        0.028682                0.745079   \n",
       "2                                        0.042667                0.614816   \n",
       "3                                        0.052408                0.766549   \n",
       "4                                        0.022727                0.840147   \n",
       "...                                           ...                     ...   \n",
       "14635                                    0.854048                0.042256   \n",
       "14636                                    0.020498                0.976462   \n",
       "14637                                    0.128583                0.571948   \n",
       "14638                                    0.016746                0.915721   \n",
       "14639                                    0.078819                0.485328   \n",
       "\n",
       "       XGBoost_prediction_neut  XGBoost_prediction_pos  \\\n",
       "0                     0.348488                0.082174   \n",
       "1                     0.164476                0.090446   \n",
       "2                     0.365109                0.020074   \n",
       "3                     0.120340                0.113111   \n",
       "4                     0.057549                0.102304   \n",
       "...                        ...                     ...   \n",
       "14635                 0.153000                0.804744   \n",
       "14636                 0.015679                0.007858   \n",
       "14637                 0.277073                0.150979   \n",
       "14638                 0.064107                0.020172   \n",
       "14639                 0.458647                0.056024   \n",
       "\n",
       "       Light_GBM_prediction_neg  Light_GBM_prediction_neut  \\\n",
       "0                      0.658466                   0.275765   \n",
       "1                      0.717759                   0.146752   \n",
       "2                      0.614650                   0.358835   \n",
       "3                      0.752354                   0.146953   \n",
       "4                      0.862668                   0.043995   \n",
       "...                         ...                        ...   \n",
       "14635                  0.047342                   0.221495   \n",
       "14636                  0.957470                   0.030969   \n",
       "14637                  0.333125                   0.350045   \n",
       "14638                  0.918684                   0.072807   \n",
       "14639                  0.368919                   0.558795   \n",
       "\n",
       "       Light_GBM_prediction_pos  polarity  subjectivity  vader_sentiment  \n",
       "0                      0.065769    0.0000      0.000000           0.0000  \n",
       "1                      0.135489    0.0000      0.000000           0.0000  \n",
       "2                      0.026515   -0.3125      0.687500           0.0000  \n",
       "3                      0.100694    0.0000      0.000000           0.0000  \n",
       "4                      0.093338   -0.3500      0.383333          -0.5423  \n",
       "...                         ...       ...           ...              ...  \n",
       "14635                  0.731164    0.0000      0.000000           0.3612  \n",
       "14636                  0.011561   -0.3000      0.600000          -0.1027  \n",
       "14637                  0.316829    0.0000      0.000000           0.0000  \n",
       "14638                  0.008508    0.0000      0.000000           0.2960  \n",
       "14639                  0.072286    0.0000      0.000000           0.0772  \n",
       "\n",
       "[14640 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome of training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.93      0.86      9178\n",
      "     neutral       0.66      0.46      0.54      3099\n",
      "    positive       0.80      0.60      0.68      2363\n",
      "\n",
      "    accuracy                           0.78     14640\n",
      "   macro avg       0.75      0.66      0.70     14640\n",
      "weighted avg       0.77      0.78      0.77     14640\n",
      "\n",
      "test average accuracy  0.7793715846994536\n",
      "[[8573  440  165]\n",
      " [1478 1422  199]\n",
      " [ 671  277 1415]]\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(silent=True,task_type=\"CPU\")\n",
    "model =LogisticRegression()\n",
    "predictions=run_features(df_copy,model,splits, features=model_predicted_names,vectorise=False)\n",
    "print_model_performance(df_copy[target_feature],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linear_regression_prediction_neg', 'linear_regression_prediction_neut', 'linear_regression_prediction_pos', 'gradient_boosted_classifier_prediction_neg', 'gradient_boosted_classifier_prediction_neut', 'gradient_boosted_classifier_prediction_pos', 'XGBoost_prediction_neg', 'XGBoost_prediction_neut', 'XGBoost_prediction_pos', 'Light_GBM_prediction_neg', 'Light_GBM_prediction_neut', 'Light_GBM_prediction_pos', 'polarity', 'subjectivity', 'vader_sentiment']\n"
     ]
    }
   ],
   "source": [
    "print(model_predicted_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>linear_regression_prediction_neg</th>\n",
       "      <th>linear_regression_prediction_neut</th>\n",
       "      <th>linear_regression_prediction_pos</th>\n",
       "      <th>gradient_boosted_classifier_prediction_neg</th>\n",
       "      <th>gradient_boosted_classifier_prediction_neut</th>\n",
       "      <th>gradient_boosted_classifier_prediction_pos</th>\n",
       "      <th>XGBoost_prediction_neg</th>\n",
       "      <th>XGBoost_prediction_neut</th>\n",
       "      <th>XGBoost_prediction_pos</th>\n",
       "      <th>Light_GBM_prediction_neg</th>\n",
       "      <th>Light_GBM_prediction_neut</th>\n",
       "      <th>Light_GBM_prediction_pos</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.797402</td>\n",
       "      <td>0.163446</td>\n",
       "      <td>0.039152</td>\n",
       "      <td>0.765865</td>\n",
       "      <td>0.186492</td>\n",
       "      <td>0.047643</td>\n",
       "      <td>0.569338</td>\n",
       "      <td>0.348488</td>\n",
       "      <td>0.082174</td>\n",
       "      <td>0.658466</td>\n",
       "      <td>0.275765</td>\n",
       "      <td>0.065769</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica plu youv ad commerci experi tacki</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.768217</td>\n",
       "      <td>0.103630</td>\n",
       "      <td>0.128153</td>\n",
       "      <td>0.859047</td>\n",
       "      <td>0.112271</td>\n",
       "      <td>0.028682</td>\n",
       "      <td>0.745079</td>\n",
       "      <td>0.164476</td>\n",
       "      <td>0.090446</td>\n",
       "      <td>0.717759</td>\n",
       "      <td>0.146752</td>\n",
       "      <td>0.135489</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>virginamerica didnt today must mean need take ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.842602</td>\n",
       "      <td>0.143376</td>\n",
       "      <td>0.014022</td>\n",
       "      <td>0.685881</td>\n",
       "      <td>0.271451</td>\n",
       "      <td>0.042667</td>\n",
       "      <td>0.614816</td>\n",
       "      <td>0.365109</td>\n",
       "      <td>0.020074</td>\n",
       "      <td>0.614650</td>\n",
       "      <td>0.358835</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica realli aggress blast obnoxi ente...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.758093</td>\n",
       "      <td>0.132768</td>\n",
       "      <td>0.109139</td>\n",
       "      <td>0.842462</td>\n",
       "      <td>0.105130</td>\n",
       "      <td>0.052408</td>\n",
       "      <td>0.766549</td>\n",
       "      <td>0.120340</td>\n",
       "      <td>0.113111</td>\n",
       "      <td>0.752354</td>\n",
       "      <td>0.146953</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica realli big bad thing</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.844298</td>\n",
       "      <td>0.036344</td>\n",
       "      <td>0.119358</td>\n",
       "      <td>0.931683</td>\n",
       "      <td>0.045590</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.840147</td>\n",
       "      <td>0.057549</td>\n",
       "      <td>0.102304</td>\n",
       "      <td>0.862668</td>\n",
       "      <td>0.043995</td>\n",
       "      <td>0.093338</td>\n",
       "      <td>-0.3500</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>americanair thank got differ flight chicago</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.089353</td>\n",
       "      <td>0.520496</td>\n",
       "      <td>0.390151</td>\n",
       "      <td>0.030135</td>\n",
       "      <td>0.115817</td>\n",
       "      <td>0.854048</td>\n",
       "      <td>0.042256</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.804744</td>\n",
       "      <td>0.047342</td>\n",
       "      <td>0.221495</td>\n",
       "      <td>0.731164</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>americanair leav  minut late flight warn commu...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.990954</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.941381</td>\n",
       "      <td>0.038121</td>\n",
       "      <td>0.020498</td>\n",
       "      <td>0.976462</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>0.957470</td>\n",
       "      <td>0.030969</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>-0.3000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>americanair pleas bring american airlin blackb...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.155839</td>\n",
       "      <td>0.627981</td>\n",
       "      <td>0.216181</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.431016</td>\n",
       "      <td>0.128583</td>\n",
       "      <td>0.571948</td>\n",
       "      <td>0.277073</td>\n",
       "      <td>0.150979</td>\n",
       "      <td>0.333125</td>\n",
       "      <td>0.350045</td>\n",
       "      <td>0.316829</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>americanair money chang flight dont answer pho...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.900002</td>\n",
       "      <td>0.090315</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>0.919845</td>\n",
       "      <td>0.063409</td>\n",
       "      <td>0.016746</td>\n",
       "      <td>0.915721</td>\n",
       "      <td>0.064107</td>\n",
       "      <td>0.020172</td>\n",
       "      <td>0.918684</td>\n",
       "      <td>0.072807</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>americanair  ppl need  know mani seat next fli...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.647267</td>\n",
       "      <td>0.294267</td>\n",
       "      <td>0.058466</td>\n",
       "      <td>0.622730</td>\n",
       "      <td>0.298452</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>0.485328</td>\n",
       "      <td>0.458647</td>\n",
       "      <td>0.056024</td>\n",
       "      <td>0.368919</td>\n",
       "      <td>0.558795</td>\n",
       "      <td>0.072286</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment  \\\n",
       "0                            virginamerica dhepburn said           neutral   \n",
       "1        virginamerica plu youv ad commerci experi tacki          positive   \n",
       "2      virginamerica didnt today must mean need take ...           neutral   \n",
       "3      virginamerica realli aggress blast obnoxi ente...          negative   \n",
       "4                     virginamerica realli big bad thing          negative   \n",
       "...                                                  ...               ...   \n",
       "14635        americanair thank got differ flight chicago          positive   \n",
       "14636  americanair leav  minut late flight warn commu...          negative   \n",
       "14637  americanair pleas bring american airlin blackb...           neutral   \n",
       "14638  americanair money chang flight dont answer pho...          negative   \n",
       "14639  americanair  ppl need  know mani seat next fli...           neutral   \n",
       "\n",
       "       linear_regression_prediction_neg  linear_regression_prediction_neut  \\\n",
       "0                              0.797402                           0.163446   \n",
       "1                              0.768217                           0.103630   \n",
       "2                              0.842602                           0.143376   \n",
       "3                              0.758093                           0.132768   \n",
       "4                              0.844298                           0.036344   \n",
       "...                                 ...                                ...   \n",
       "14635                          0.089353                           0.520496   \n",
       "14636                          0.990954                           0.006345   \n",
       "14637                          0.155839                           0.627981   \n",
       "14638                          0.900002                           0.090315   \n",
       "14639                          0.647267                           0.294267   \n",
       "\n",
       "       linear_regression_prediction_pos  \\\n",
       "0                              0.039152   \n",
       "1                              0.128153   \n",
       "2                              0.014022   \n",
       "3                              0.109139   \n",
       "4                              0.119358   \n",
       "...                                 ...   \n",
       "14635                          0.390151   \n",
       "14636                          0.002701   \n",
       "14637                          0.216181   \n",
       "14638                          0.009683   \n",
       "14639                          0.058466   \n",
       "\n",
       "       gradient_boosted_classifier_prediction_neg  \\\n",
       "0                                        0.765865   \n",
       "1                                        0.859047   \n",
       "2                                        0.685881   \n",
       "3                                        0.842462   \n",
       "4                                        0.931683   \n",
       "...                                           ...   \n",
       "14635                                    0.030135   \n",
       "14636                                    0.941381   \n",
       "14637                                    0.440400   \n",
       "14638                                    0.919845   \n",
       "14639                                    0.622730   \n",
       "\n",
       "       gradient_boosted_classifier_prediction_neut  \\\n",
       "0                                         0.186492   \n",
       "1                                         0.112271   \n",
       "2                                         0.271451   \n",
       "3                                         0.105130   \n",
       "4                                         0.045590   \n",
       "...                                            ...   \n",
       "14635                                     0.115817   \n",
       "14636                                     0.038121   \n",
       "14637                                     0.431016   \n",
       "14638                                     0.063409   \n",
       "14639                                     0.298452   \n",
       "\n",
       "       gradient_boosted_classifier_prediction_pos  XGBoost_prediction_neg  \\\n",
       "0                                        0.047643                0.569338   \n",
       "1                                        0.028682                0.745079   \n",
       "2                                        0.042667                0.614816   \n",
       "3                                        0.052408                0.766549   \n",
       "4                                        0.022727                0.840147   \n",
       "...                                           ...                     ...   \n",
       "14635                                    0.854048                0.042256   \n",
       "14636                                    0.020498                0.976462   \n",
       "14637                                    0.128583                0.571948   \n",
       "14638                                    0.016746                0.915721   \n",
       "14639                                    0.078819                0.485328   \n",
       "\n",
       "       XGBoost_prediction_neut  XGBoost_prediction_pos  \\\n",
       "0                     0.348488                0.082174   \n",
       "1                     0.164476                0.090446   \n",
       "2                     0.365109                0.020074   \n",
       "3                     0.120340                0.113111   \n",
       "4                     0.057549                0.102304   \n",
       "...                        ...                     ...   \n",
       "14635                 0.153000                0.804744   \n",
       "14636                 0.015679                0.007858   \n",
       "14637                 0.277073                0.150979   \n",
       "14638                 0.064107                0.020172   \n",
       "14639                 0.458647                0.056024   \n",
       "\n",
       "       Light_GBM_prediction_neg  Light_GBM_prediction_neut  \\\n",
       "0                      0.658466                   0.275765   \n",
       "1                      0.717759                   0.146752   \n",
       "2                      0.614650                   0.358835   \n",
       "3                      0.752354                   0.146953   \n",
       "4                      0.862668                   0.043995   \n",
       "...                         ...                        ...   \n",
       "14635                  0.047342                   0.221495   \n",
       "14636                  0.957470                   0.030969   \n",
       "14637                  0.333125                   0.350045   \n",
       "14638                  0.918684                   0.072807   \n",
       "14639                  0.368919                   0.558795   \n",
       "\n",
       "       Light_GBM_prediction_pos  polarity  subjectivity  vader_sentiment  \n",
       "0                      0.065769    0.0000      0.000000           0.0000  \n",
       "1                      0.135489    0.0000      0.000000           0.0000  \n",
       "2                      0.026515   -0.3125      0.687500           0.0000  \n",
       "3                      0.100694    0.0000      0.000000           0.0000  \n",
       "4                      0.093338   -0.3500      0.383333          -0.5423  \n",
       "...                         ...       ...           ...              ...  \n",
       "14635                  0.731164    0.0000      0.000000           0.3612  \n",
       "14636                  0.011561   -0.3000      0.600000          -0.1027  \n",
       "14637                  0.316829    0.0000      0.000000           0.0000  \n",
       "14638                  0.008508    0.0000      0.000000           0.2960  \n",
       "14639                  0.072286    0.0000      0.000000           0.0772  \n",
       "\n",
       "[14640 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
