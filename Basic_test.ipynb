{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "import string\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_variable='clean_text'\n",
    "target_feature='category'\n",
    "stop_words = stopwords.words('english') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"(http\\S+|http)\", \"\", txt) # remove links \n",
    "    txt = re.sub('[^a-zA-Z ]+', '', txt) #only allows for letters\n",
    "    txt = ' '.join([PorterStemmer().stem(word=word) for word in txt.split(\" \") if word not in stop_words ]) # stem & remove stop words\n",
    "    #made redudent by only accepting text\n",
    "    '''\n",
    "    txt = re.sub(r\"(@\\S+)\", \"\", txt)  # remove hashtags\n",
    "    txt = txt.translate(str.maketrans('', '', string.punctuation)) # remove punctuations \n",
    " \n",
    "    \n",
    "    txt = ''.join([i for i in txt if not i.isdigit()]).strip() # remove digits ()\n",
    "    '''\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modi promis minimum govern maximum govern expe...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk nonsens continu drama vote modi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say vote modi  welcom bjp told rahul main camp...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ask support prefix chowkidar name modi great s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer among power world leader today trump pu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162968</th>\n",
       "      <td>crore paid neerav modi recov congress leader ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162969</th>\n",
       "      <td>dear rss terrorist payal gawar modi kill  plu ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162970</th>\n",
       "      <td>cover interact forum left</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162971</th>\n",
       "      <td>big project came india modi dream project happ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162972</th>\n",
       "      <td>ever listen like gurukul disciplin maintain ev...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162973 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "0       modi promis minimum govern maximum govern expe...      -1.0\n",
       "1                   talk nonsens continu drama vote modi        0.0\n",
       "2       say vote modi  welcom bjp told rahul main camp...       1.0\n",
       "3       ask support prefix chowkidar name modi great s...       1.0\n",
       "4       answer among power world leader today trump pu...       1.0\n",
       "...                                                   ...       ...\n",
       "162968   crore paid neerav modi recov congress leader ...      -1.0\n",
       "162969  dear rss terrorist payal gawar modi kill  plu ...      -1.0\n",
       "162970                         cover interact forum left        0.0\n",
       "162971  big project came india modi dream project happ...       0.0\n",
       "162972  ever listen like gurukul disciplin maintain ev...       1.0\n",
       "\n",
       "[162973 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_name='datasets/Twitter and Reddit Sentimental analysis Dataset'\n",
    "# all_files = os.listdir(directory_name)   # imagine you're one directory above test dir\n",
    "# txt_files = filter(lambda x: x[-4:] == '.txt', all_files)\n",
    "# dictionary=[]\n",
    "\n",
    "# for filename in txt_files:\n",
    "# \tf = open(directory_name+filename,'r')\n",
    "# \tdictionary.append({'ArticleId':filename[0:-4],'tweet_contents':f.read()})\n",
    "# \tf.close()\n",
    "# tweet_df = pd.DataFrame(dictionary)\n",
    "data_df = pd.read_csv(\"datasets/Twitter and Reddit Sentimental analysis Dataset/Twitter_Data.csv\") \n",
    "#cleaning type of data\n",
    "data_df[text_variable] = data_df[text_variable].astype(str)\n",
    "data_df[text_variable] = data_df[text_variable].apply(clean_text)  \n",
    "# dropping nans and reindexing\n",
    "data_df = data_df.dropna()\n",
    "data_df=data_df.reset_index(drop=True)\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_test_data(full_df):   \n",
    "#     y = full_df[target_feature]   # define target and feature column\n",
    "#     X = full_df[text_variable]\n",
    "     \n",
    "#     text_train, text_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42,stratify=y)  \n",
    "#     vect = CountVectorizer(min_df=5, ngram_range=(1, 4)) # create Count vectorizer.\n",
    "#     X_train = vect.fit(text_train).transform(text_train) # transform text_train  into a vector \n",
    "#     X_test = vect.transform(text_test) \n",
    "#     feature_names = vect.get_feature_names() # to return all words used in vectorizer\n",
    "  \n",
    "#     return X_train, X_test, y_train, y_test, feature_names\n",
    "def train_test_crosval(train, test):\n",
    "#     balanced_train = balance(train)\n",
    "    y_train = train[target_feature]   \n",
    "    text_train = train[text_variable]\n",
    "    y_test = test[target_feature]   \n",
    "    text_test = test[text_variable]\n",
    "     \n",
    "    #text_train, text_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42,stratify=y)  \n",
    "    vect = TfidfVectorizer(min_df=5, ngram_range=(1, 4)) # create Count vectorizer.\n",
    "    X_train = vect.fit(text_train).transform(text_train) # transform text_train  into a vector \n",
    "    X_test = vect.transform(text_test) \n",
    "    feature_names = vect.get_feature_names() # to return all words used in vectorizer\n",
    "  \n",
    "    return X_train, X_test, y_train, y_test, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_performance(model,X_train,X_test,y_train,y_test):\n",
    "    training_sample = model.predict(X_train)\n",
    "    testing_sample = model.predict(X_test)\n",
    "    print('training ')\n",
    "    #print(classification_report(training_sample, y_train))  #uncomment if you want to see full report \n",
    "    print('train accuracy ',accuracy_score(training_sample, y_train))\n",
    "    #print('train precision_score ',precision_score(training_sample, y_train)) \n",
    "    #print('train recall score',recall_score(training_sample, y_train)) \n",
    "    \n",
    "    print('\\n testing  ')\n",
    "    print(classification_report(testing_sample, y_test))   #uncomment if you want to see full report \n",
    "    print('test average accuracy ',accuracy_score(testing_sample, y_test))\n",
    "    #print('test average precision_score ',precision_score(testing_sample, y_test)) \n",
    "    #print('test average recall score',recall_score(testing_sample, y_test)) \n",
    "    #print('test AUC ',roc_auc_score(testing_sample, y_test))\n",
    "    \n",
    "    print(confusion_matrix( y_test,testing_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#y = id_tweets['Tone']   # define target and feature column\n",
    "#X = id_tweets['cleaned_text']\n",
    "to_dataset=data_df.copy()\n",
    "#resample_sizes=[1000,1500,2000,2500]\n",
    "# resample_sizes=[1000]\n",
    "cv = KFold(n_splits=2, random_state=42, shuffle=False)\n",
    "full_prediciton=[]\n",
    "# for resample_size in resample_sizes:\n",
    "for train_index, test_index in cv.split(to_dataset):\n",
    "    train, test = to_dataset.loc[train_index], to_dataset.loc[test_index]\n",
    "\n",
    "    X_train, X_test, y_train, y_test, feature_names=train_test_crosval(train,test)\n",
    "    model = LogisticRegressionCV()\n",
    "    #to run faster\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    #print_model_performance(lgstc, X_train, X_test, y_train, y_test)\n",
    "    prediction = lgstc.predict(X_test)\n",
    "    full_prediciton.append(prediction)\n",
    "predictions=[]\n",
    "\n",
    "for set_of_prediction in full_prediciton:\n",
    "    for predicted in set_of_prediction:\n",
    "        predictions.append(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modi promis minimum govern maximum govern expe...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk nonsens continu drama vote modi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say vote modi  welcom bjp told rahul main camp...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ask support prefix chowkidar name modi great s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer among power world leader today trump pu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162968</th>\n",
       "      <td>crore paid neerav modi recov congress leader ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162969</th>\n",
       "      <td>dear rss terrorist payal gawar modi kill  plu ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162970</th>\n",
       "      <td>cover interact forum left</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162971</th>\n",
       "      <td>big project came india modi dream project happ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162972</th>\n",
       "      <td>ever listen like gurukul disciplin maintain ev...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162973 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "0       modi promis minimum govern maximum govern expe...      -1.0\n",
       "1                   talk nonsens continu drama vote modi        0.0\n",
       "2       say vote modi  welcom bjp told rahul main camp...       1.0\n",
       "3       ask support prefix chowkidar name modi great s...       1.0\n",
       "4       answer among power world leader today trump pu...       1.0\n",
       "...                                                   ...       ...\n",
       "162968   crore paid neerav modi recov congress leader ...      -1.0\n",
       "162969  dear rss terrorist payal gawar modi kill  plu ...      -1.0\n",
       "162970                         cover interact forum left        0.0\n",
       "162971  big project came india modi dream project happ...       0.0\n",
       "162972  ever listen like gurukul disciplin maintain ev...       1.0\n",
       "\n",
       "[162973 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to_dataset.isnull().sum(axis = 0)\n",
    "df_copy=to_dataset.copy()\n",
    "df_copy['prediction']=predictions\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['prediction']=output_df['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome of training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.79      0.58      0.67     35510\n",
      "         0.0       0.75      0.82      0.78     55213\n",
      "         1.0       0.81      0.86      0.83     72250\n",
      "\n",
      "    accuracy                           0.78    162973\n",
      "   macro avg       0.78      0.75      0.76    162973\n",
      "weighted avg       0.78      0.78      0.78    162973\n",
      "\n",
      "test average accuracy  0.7839519429598768\n",
      "[[20467  8300  6743]\n",
      " [ 2011 45241  7961]\n",
      " [ 3450  6745 62055]]\n"
     ]
    }
   ],
   "source": [
    "print('outcome of training')\n",
    "print(classification_report( df_copy[target_feature],output_df['prediction']))   #uncomment if you want to see full report \n",
    "print('test average accuracy ',accuracy_score( df_copy[target_feature],output_df['prediction']))\n",
    "print(confusion_matrix( df_copy[target_feature],output_df['prediction']))\n",
    "# df_copy['prediction']=predictions\n",
    "# predictions.clear()\n",
    "# full_prediciton.clear()\n",
    "output_df=df_copy.drop(text_variable, axis=1)\n",
    "# predictions.clear()\n",
    "# full_prediciton.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['polarity']=df_copy[text_variable].apply(lambda text: TextBlob(text).sentiment.polarity)\n",
    "df_copy['subjectivity']=df_copy[text_variable].apply(lambda text: TextBlob(text).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sentiment_analyzer_scores(text, threshold=0.05, engl=True):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "    if engl:\n",
    "        trans = text\n",
    "    else:\n",
    "        trans = translator.translate(text).text\n",
    "\n",
    "    score = analyser.polarity_scores(trans)\n",
    "    lb = score['compound']\n",
    "    return lb\n",
    "    if lb >= threshold:\n",
    "        return 1\n",
    "    elif (lb > -threshold) and (lb < threshold):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['vader_sentiment']=df_copy[text_variable].apply(lambda tweet: sentiment_analyzer_scores(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>prediction</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modi promis minimum govern maximum govern expe...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk nonsens continu drama vote modi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say vote modi  welcom bjp told rahul main camp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ask support prefix chowkidar name modi great s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer among power world leader today trump pu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162968</th>\n",
       "      <td>crore paid neerav modi recov congress leader ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.291667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162969</th>\n",
       "      <td>dear rss terrorist payal gawar modi kill  plu ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.9062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162970</th>\n",
       "      <td>cover interact forum left</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162971</th>\n",
       "      <td>big project came india modi dream project happ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162972</th>\n",
       "      <td>ever listen like gurukul disciplin maintain ev...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162973 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category  \\\n",
       "0       modi promis minimum govern maximum govern expe...      -1.0   \n",
       "1                   talk nonsens continu drama vote modi        0.0   \n",
       "2       say vote modi  welcom bjp told rahul main camp...       1.0   \n",
       "3       ask support prefix chowkidar name modi great s...       1.0   \n",
       "4       answer among power world leader today trump pu...       1.0   \n",
       "...                                                   ...       ...   \n",
       "162968   crore paid neerav modi recov congress leader ...      -1.0   \n",
       "162969  dear rss terrorist payal gawar modi kill  plu ...      -1.0   \n",
       "162970                         cover interact forum left        0.0   \n",
       "162971  big project came india modi dream project happ...       0.0   \n",
       "162972  ever listen like gurukul disciplin maintain ev...       1.0   \n",
       "\n",
       "        prediction  polarity  subjectivity  vader_sentiment  \n",
       "0             -1.0 -0.500000      1.000000          -0.3612  \n",
       "1              0.0  0.000000      0.000000           0.0000  \n",
       "2              1.0  0.166667      0.333333           0.4404  \n",
       "3             -1.0  0.450000      0.566667           0.8555  \n",
       "4              1.0  0.000000      0.000000           0.0000  \n",
       "...            ...       ...           ...              ...  \n",
       "162968        -1.0 -0.291667      0.541667          -0.1027  \n",
       "162969        -1.0  0.000000      0.000000          -0.9062  \n",
       "162970         0.0  0.000000      0.000000           0.0000  \n",
       "162971         0.0  0.000000      0.100000           0.2500  \n",
       "162972         1.0  0.450000      0.550000          -0.1531  \n",
       "\n",
       "[162973 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amalgamate=df_copy.copy()\n",
    "df_amalgamate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_crosval_prob(train,test, features):\n",
    "#     balanced_train = balance(train)\n",
    "    y_train = train[target_feature]   \n",
    "    X_train = train[features]\n",
    "    y_test = test[target_feature]   \n",
    "    X_test = test[features]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=2, random_state=42, shuffle=False)\n",
    "full_prediciton=[]\n",
    "features=['polarity','subjectivity','prediction','vader_sentiment']\n",
    "# for resample_size in resample_sizes:\n",
    "for train_index, test_index in cv.split(df_amalgamate):\n",
    "    train, test = df_amalgamate.loc[train_index], df_amalgamate.loc[test_index]\n",
    "\n",
    "    X_train, X_test, y_train, y_test=train_test_crosval_prob(train,test,features)\n",
    "    model = LogisticRegressionCV()\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    #print_model_performance(lgstc, X_train, X_test, y_train, y_test)\n",
    "    prediction = lgstc.predict(X_test)\n",
    "    full_prediciton.append(prediction)\n",
    "predictions=[]\n",
    "\n",
    "for set_of_prediction in full_prediciton:\n",
    "    for predicted in set_of_prediction:\n",
    "        predictions.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amalgamate['final_prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome of training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.79      0.58      0.67     35510\n",
      "         0.0       0.75      0.82      0.78     55213\n",
      "         1.0       0.81      0.86      0.83     72250\n",
      "\n",
      "    accuracy                           0.78    162973\n",
      "   macro avg       0.78      0.75      0.76    162973\n",
      "weighted avg       0.78      0.78      0.78    162973\n",
      "\n",
      "test average accuracy  0.7840133028170311\n",
      "[[20494  8245  6771]\n",
      " [ 2036 45212  7965]\n",
      " [ 3457  6726 62067]]\n"
     ]
    }
   ],
   "source": [
    "print('outcome of training')\n",
    "print(classification_report( df_amalgamate[target_feature],df_amalgamate['final_prediction']))   #uncomment if you want to see full report \n",
    "print('test average accuracy ',accuracy_score( df_amalgamate[target_feature],df_amalgamate['final_prediction']))\n",
    "print(confusion_matrix( df_amalgamate[target_feature],df_amalgamate['final_prediction']))\n",
    "# df_amalgamate['prediction']=predictions\n",
    "# predictions.clear()\n",
    "# full_prediciton.clear()\n",
    "# output_df=df_copy.drop(text_variable, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
